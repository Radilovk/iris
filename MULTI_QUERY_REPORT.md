# Multi-Query Report Generation

## Проблем

Предишният подход изпращаше целия контекст (потребителски данни, анализи на очите, база знания, препоръки) в една голяма заявка към AI модела. Това водеше до:

- Претоварване на модела с твърде много информация
- Невъзможност за модела да се фокусира върху конкретни аспекти
- По-бедни и повърхностни доклади
- Липса на дълбочина в препоръките

## Решение

Новият подход разделя генерирането на доклада на **4 фокусирани стъпки**, всяка с конкретна цел и ограничен контекст:

### Стъпка 1: Конституционална синтеза

**Цел:** Обединяване на находките от двете очи в цялостна конституционална оценка

**Контекст:**

- Конституционален анализ на лявото око
- Конституционален анализ на дясното око
- Основни потребителски данни (възраст, цели, здравно състояние)
- Релевантна база знания (ограничена до 3000 символа)

**Резултат:**

```json
{
  "constitutional_type": "Кратко описание",
  "detailed_analysis": "Детайлен параграф (150-200 думи)",
  "predispositions": ["Списък от предразположения"],
  "psychological_profile": "Психологически профил",
  "connection_to_goals": "Връзка с целите на потребителя"
}
```

### Стъпка 2: Интерпретация на знаците

**Цел:** Анализ на здравните импликации на идентифицираните знаци

**Контекст:**

- Конституционална синтеза от стъпка 1
- Всички идентифицирани знаци (до 4000 символа)
- Потребителски данни (цели, здравно състояние, стрес, сън)
- Релевантна база знания (до 3000 символа)

**Резултат:**

```json
{
  "priority_systems": [
    {
      "system": "Име на системата",
      "why_priority": "Защо е приоритет",
      "related_signs": ["Свързани знаци"]
    }
  ],
  "eliminative_channels": {
    "intestines": "Оценка и препоръки",
    "kidneys": "Оценка и препоръки",
    "lymphatic": "Оценка и препоръки",
    "lungs": "Оценка и препоръки",
    "skin": "Оценка и препоръки"
  },
  "key_findings": [...],
  "synergistic_effect": "Синергичен ефект"
}
```

### Стъпка 3: Персонализирани препоръки

**Цел:** Създаване на конкретни, приложими препоръки

**Контекст:**

- Интерпретация на знаците от стъпка 2
- Конституционална синтеза от стъпка 1
- Детайлни потребителски данни (до 3000 символа)
- База с препоръки (до 4000 символа)

**Резултат:**

```json
{
  "action_plan": {
    "immediate": ["Незабавни действия"],
    "short_term": ["Краткосрочни"],
    "medium_term": ["Средносрочни"],
    "progress_indicators": ["Индикатори"]
  },
  "nutrition": {...},
  "herbs_and_supplements": {...},
  "holistic_recommendations": {...},
  "follow_up": {...}
}
```

### Стъпка 4: Финално сглобяване

**Цел:** Обединяване на всички компоненти в структуриран доклад

**Контекст:**

- Конституционална синтеза
- Интерпретация на знаците
- Препоръки
- Потребителско име
- Дисклеймър

**Резултат:** Финален структуриран доклад с всички секции

## Активиране

### В конфигурацията (iris_config_kv.json):

```json
{
  "use_multi_query_report": true
}
```

### По подразбиране:

- `use_multi_query_report` не е зададен или е `false` → използва се старият подход (единична заявка)
- `use_multi_query_report` е `true` → използва се новият подход (4 заявки)

## Предимства

### 1. По-високо качество на анализа

Всяка стъпка получава само релевантния контекст, което позволява на AI модела да се фокусира върху конкретната задача.

### 2. По-детайлни препоръки

Отделната стъпка за препоръки позволява генериране на по-конкретни и приложими съвети.

### 3. По-добро използване на токени

Въпреки че общият брой токени може да е по-висок, всяка заявка използва токените си по-ефективно.

### 4. Модулност

Лесно се добавят нови стъпки или модифицират съществуващите.

### 5. Обратна съвместимост

Старият подход продължава да работи за съществуващи инсталации.

## Разлики в токени

### Стар подход (единична заявка):

```
Входящи токени: ~15,000-20,000
Изходящи токени: ~2,000-3,000
Общо: ~17,000-23,000
```

### Нов подход (4 заявки):

```
Стъпка 1: Вх ~4,000, Изх ~500
Стъпка 2: Вх ~5,000, Изх ~700
Стъпка 3: Вх ~6,000, Изх ~800
Стъпка 4: Вх ~3,000, Изх ~1,500
Общо: Вх ~18,000, Изх ~3,500
Общо токени: ~21,500
```

**Забележка:** Въпреки подобния общ брой токени, качеството на изхода е значително по-високо поради фокусирания контекст във всяка стъпка.

## Мониторинг

За да проверите дали multi-query режимът работи, следете логовете на worker-а:

```bash
wrangler tail
```

При активиран multi-query режим ще видите 4 последователни AI заявки вместо 1.

## Troubleshooting

### Докладът е празен или невалиден

- Проверете дали всички 4 стъпки се изпълняват успешно
- Уверете се че AI моделът е правилно конфигуриран
- Проверете дали API ключът е валиден

### Rate limit грешки

- Multi-query подходът прави 4 заявки последователно
- При достигане на rate limit, системата автоматично прави retry с exponential backoff
- Уверете се че имате достатъчен API quota

### Бавно изпълнение

- 4 последователни заявки отнемат повече време от 1 заявка
- Очаквано време за генериране: 20-40 секунди (вместо 10-15 секунди)
- Качеството оправдава допълнителното време

## Бъдещи подобрения

- [ ] Паралелно изпълнение на стъпки 1 и 2 (където е възможно)
- [ ] Кеширане на междинни резултати
- [ ] Адаптивно избиране на брой стъпки според сложността
- [ ] Streaming на междинните резултати към потребителя
