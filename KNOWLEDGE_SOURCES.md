# Източници на знания в AI анализа

## Общ преглед

Iris-Holistica AI използва многослоен подход за генериране на холистични доклади, комбинирайки различни източници на знания за максимална точност и персонализация.

## Използвани източници

### 1. RAG Памет (Retrieval Augmented Generation)
**Описание:** Специализирана база данни за иридология, съхранявана в Cloudflare KV хранилище.

**Съдържание:**
- `iris_diagnostic_map` - Топографска карта на ириса със зони и техните проекции
- `holistic_interpretation_knowledge` - Холистична интерпретация на знаци и симптоми
- Конституционални типове (цветови и структурни)
- Знаци и тяхната диагностична стойност (лакуни, пръстени, пигменти и др.)
- Елиминативни канали и тяхната роля

**Как се използва:**
1. При визуалния анализ - предоставя контекст за разпознаване на знаци
2. При валидация - обогатява идентифицираните знаци с допълнителна информация
3. При генериране на доклад - филтрира се според ключови думи от находките

**Типично процентно участие:** 40-60% от входните източници

### 2. База с препоръки (Remedy Base)
**Описание:** Колекция от холистични терапии, хранителни насоки и билкови препоръки.

**Съдържание:**
- Детокс протоколи
- Билкови терапии
- Хранителни препоръки
- Добавки и тяхното приложение
- Животни навици и упражнения

**Как се използва:**
1. Филтрира се според идентифицираните знаци и техните remedy_link връзки
2. Персонализира се според целите на потребителя
3. Генерира конкретни, приложими препоръки

**Типично процентно участие:** 30-40% от входните източници

### 3. Интернет търсене (Internet Search)
**Описание:** Външни актуални източници през web research API (опционално).

**Съдържание:**
- Научни статии
- Актуални изследвания
- Клинични протоколи
- Съвременни медицински насоки

**Как се използва:**
1. Активира се само ако е конфигуриран `WEB_RESEARCH_API_KEY`
2. Търси според ключови думи от находките
3. Добавя до 3 външни източника (ограничен до 8 сек таймаут)
4. При липса на резултати - използва се fallback контекст

**Типично процентно участие:** 0-20% от входните източници (зависи от конфигурация)

### 4. LLM Знания (Language Model Knowledge)
**Описание:** Вградени знания на AI модела и синтеза на информацията.

**Съдържание:**
- Обучение на модела (Gemini/OpenAI) върху обширни медицински данни
- Синтеза и интеграция на всички източници
- Генериране на персонализиран текст
- Логическо свързване на находки
- Контекстуално разбиране

**Как се използва:**
1. При визуален анализ - разпознава знаци на снимките
2. При синтеза - комбинира всички източници в кохерентен доклад
3. При персонализация - адаптира препоръките към конкретния случай
4. При генериране - създава лесен за четене, структуриран текст

**Типично процентно участие:** 25% допълнителна стойност при синтезата

## Логична последователност на анализа

### Стъпка 1: Визуален анализ
- **Използва:** RAG контекст + LLM визуални възможности
- **Цел:** Идентифициране на знаци в снимките
- **Изход:** Конституционален анализ + Списък със знаци

### Стъпка 2: Валидация и обогатяване
- **Използва:** RAG diagnostic map
- **Цел:** Валидиране на знаците и добавяне на допълнителна информация
- **Изход:** Обогатени знаци с зони, интензитет, интерпретация

### Стъпка 3: Контекстуализация
- **Използва:** RAG knowledge + Remedy base + (опционално) Internet search
- **Цел:** Избиране на релевантна информация според находките
- **Изход:** Филтрирана база знания и препоръки

### Стъпка 4: Синтеза и генериране
- **Използва:** Всички източници + LLM синтеза
- **Цел:** Създаване на персонализиран, структуриран доклад
- **Изход:** Финален JSON доклад с анализ и препоръки

## Процентно разпределение

### При активно интернет търсене:
```
RAG Памет:           45%
База с препоръки:    25%
Интернет търсене:    5%
LLM Синтеза:         25%
```

### Без интернет търсене (типичен случай):
```
RAG Памет:           50%
База с препоръки:    25%
Интернет търсене:    0%
LLM Синтеза:         25%
```

### В Multi-Query режим:
```
RAG Памет:           55%
База с препоръки:    20%
Интернет търсене:    0%
LLM Синтеза:         25%
```

**Забележка:** Процентите показват разпределението на входните източници. LLM добавя допълнителна стойност (25%) чрез синтеза, генериране и персонализация на информацията от всички източници.

## Валидация на логиката

✅ **Последователността е правилна:**
1. Започва с визуален анализ (най-обективен)
2. Валидира находките с RAG база (експертна верификация)
3. Контекстуализира с релевантни знания (персонализация)
4. Синтезира всичко в кохерентен доклад (LLM възможности)

✅ **Разпределението е оптимално:**
- RAG памет има най-голям дял (50%+) - гарантира експертни знания
- Remedy base осигурява практични препоръки (20-25%)
- Internet search добавя актуалност когато е наличен (0-20%)
- LLM синтезата интегрира всичко и добавя стойност (25%)

## Как да видите метриките

Всеки генериран доклад включва поле `_analytics.knowledge_sources` със следната информация:

```json
{
  "_analytics": {
    "knowledge_sources": {
      "sources_used": {
        "rag_memory": {
          "used": true,
          "entries_count": 12,
          "percentage": 50,
          "description": "RAG памет (Retrieval Augmented Generation) - интерпретационна база данни за иридология"
        },
        "remedy_base": {
          "used": true,
          "entries_count": 6,
          "percentage": 25,
          "description": "База данни с препоръки и холистични терапии"
        },
        "internet_search": {
          "used": false,
          "enabled": false,
          "entries_count": 0,
          "percentage": 0,
          "description": "Външно интернет търсене за актуални източници"
        },
        "llm_knowledge": {
          "used": true,
          "percentage": 25,
          "description": "Вградени знания на AI модела и синтеза на информацията"
        }
      },
      "analysis_flow": {
        "sequence": [
          "1. Визуален анализ с AI модел (използва RAG контекст за разпознаване на знаци)",
          "2. Валидация и обогатяване на знаците (използва RAG diagnostic map)",
          "3. Филтриране на релевантна RAG база знания (според ключови думи)",
          "4. Извличане на външни източници (ако е активирано интернет търсене)",
          "5. Генериране на доклад (синтеза от всички източници чрез LLM)"
        ],
        "logic_validation": {
          "is_correct": true,
          "notes": "Логиката следва правилната последователност: анализ → обогатяване → контекстуализация → синтеза"
        }
      },
      "percentage_breakdown": {
        "rag_memory": "50%",
        "remedy_base": "25%",
        "internet_search": "0%",
        "llm_knowledge": "25%"
      }
    }
  }
}
```

## Конфигурация

### Активиране на интернет търсене:

В `wrangler.toml` или environment variables:
```toml
[vars]
WEB_RESEARCH_ENDPOINT = "https://serper.dev/search"

[secrets]
WEB_RESEARCH_API_KEY = "your-api-key"
```

### Контрол на RAG контекст:

В `iris_config_kv.json`:
```json
{
  "max_context_entries": 6
}
```

Препоръчителни стойности:
- `4` за компактни модели (gemini-1.5-flash, gpt-4o-mini)
- `6` за балансирани модели (gemini-1.5-pro, gpt-4o) - по подразбиране
- `8-10` за разширени модели с голям контекст

## Заключение

Iris-Holistica AI използва научно обоснован multi-source подход който:
1. ✅ **Използва RAG памет** - да, като основен източник (50%+)
2. ✅ **Използва LLM знания** - да, за визуален анализ и синтеза (25%)
3. ✅ **Използва интернет търсене** - опционално, когато е конфигурирано (0-20%)
4. ✅ **Логиката е правилна** - валидирана последователност от анализ към синтеза
5. ✅ **Разпределението е оптимално** - балансирано между експертни знания и AI възможности

Този подход осигурява максимална точност, актуалност и персонализация на генерираните доклади.
