# Отговор: Източници на знания в AI анализа

## Въпрос
При AI анализа използват ли се RAG памет, LLM знания, Интернет търсене? Правилна ли е логиката и последователността и как е разпределено процентно?

## Кратък отговор

**ДА**, AI анализът използва всички три източника на знания:

### 1. ✅ RAG Памет (Retrieval Augmented Generation)
**Използва се:** ДА, като основен източник  
**Процентно участие:** 50-55% от входните източници  
**Съдържание:**
- Iris diagnostic map (топография на ириса)
- Holistic interpretation knowledge (интерпретация на знаци)
- Конституционални типове
- Елиминативни канали

### 2. ✅ LLM Знания (Language Model Knowledge)
**Използва се:** ДА, винаги  
**Процентно участие:** 25% синтеза и генериране  
**Роля:**
- Визуално разпознаване на знаци в снимките
- Синтеза на всички източници
- Генериране на персонализиран доклад
- Контекстуално разбиране

### 3. ✅ Интернет търсене (Internet Search)
**Използва се:** ДА, когато е конфигурирано  
**Процентно участие:** 0-20% (зависи от конфигурация)  
**Забележка:** Опционално - активира се само с `WEB_RESEARCH_API_KEY`

### 4. База с препоръки (Remedy Base)
**Използва се:** ДА  
**Процентно участие:** 20-25%  
**Съдържание:**
- Детокс протоколи
- Билкови терапии
- Хранителни препоръки

## Логика и последователност

### ✅ Логиката е ПРАВИЛНА

Системата следва научно обоснована последователност:

**Стъпка 1: Визуален анализ**
- Използва: RAG контекст + LLM възможности
- Цел: Разпознаване на знаци в снимките
- Изход: Конституционален анализ + Списък със знаци

**Стъпка 2: Валидация и обогатяване**
- Използва: RAG diagnostic map
- Цел: Верификация и обогатяване на находките
- Изход: Валидирани знаци с допълнителна информация

**Стъпка 3: Контекстуализация**
- Използва: RAG knowledge + Remedy base + (опционално) Internet search
- Цел: Филтриране на релевантна информация
- Изход: Персонализиран контекст

**Стъпка 4: Синтеза и генериране**
- Използва: Всички източници + LLM синтеза
- Цел: Създаване на финален доклад
- Изход: JSON доклад с аналитика

### ✅ Последователността е ОПТИМАЛНА

Процесът е:
1. **Обективен** - започва с визуален анализ
2. **Валидиран** - проверява находките с експертна база
3. **Персонализиран** - адаптира към конкретния случай
4. **Синтезиран** - интегрира всички източници

## Процентно разпределение

### Типичен случай (без интернет търсене):
```
┌─────────────────────────────────────────────────────┐
│ RAG Памет:           50% ████████████████████████   │
│ База с препоръки:    25% ████████████              │
│ Интернет търсене:     0%                           │
│ LLM Синтеза:         25% ████████████              │
└─────────────────────────────────────────────────────┘
```

### С активно интернет търсене:
```
┌─────────────────────────────────────────────────────┐
│ RAG Памет:           45% ██████████████████████     │
│ База с препоръки:    25% ████████████              │
│ Интернет търсене:     5% ██                        │
│ LLM Синтеза:         25% ████████████              │
└─────────────────────────────────────────────────────┘
```

### Multi-Query режим:
```
┌─────────────────────────────────────────────────────┐
│ RAG Памет:           55% ██████████████████████████ │
│ База с препоръки:    20% ██████████                │
│ Интернет търсене:     0%                           │
│ LLM Синтеза:         25% ████████████              │
└─────────────────────────────────────────────────────┘
```

## Транспарентност

Всеки генериран доклад включва секция `_analytics.knowledge_sources` с:
- Точен брой записи от всеки източник
- Процентно разпределение
- Последователност на анализа
- Валидация на логиката

Пример:
```json
{
  "_analytics": {
    "knowledge_sources": {
      "sources_used": {
        "rag_memory": {
          "used": true,
          "entries_count": 12,
          "percentage": 50
        },
        "llm_knowledge": {
          "used": true,
          "percentage": 25
        }
      },
      "analysis_flow": {
        "logic_validation": {
          "is_correct": true
        }
      }
    }
  }
}
```

## Заключение

✅ **RAG памет** - Използва се активно (50%+)  
✅ **LLM знания** - Използват се винаги (25%)  
✅ **Интернет търсене** - Използва се опционално (0-20%)  
✅ **Логиката** - Правилна и валидирана  
✅ **Последователността** - Оптимална (анализ → валидация → контекст → синтеза)  
✅ **Разпределението** - Балансирано и прозрачно

## Как да активирате интернет търсене

В `wrangler.toml`:
```toml
[vars]
WEB_RESEARCH_ENDPOINT = "https://serper.dev/search"

[secrets]
WEB_RESEARCH_API_KEY = "your-api-key"
```

## Документация

За повече детайли вижте:
- [KNOWLEDGE_SOURCES.md](KNOWLEDGE_SOURCES.md) - Пълна техническа документация
- [README.md](README.md) - Общ преглед на системата
- [MULTI_QUERY_REPORT.md](MULTI_QUERY_REPORT.md) - Multi-query режим

---

**Актуализация:** 2025-01-06  
**Статус:** ✅ Имплементирано и тествано (32/32 теста минават)
